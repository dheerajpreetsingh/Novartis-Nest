{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116149 entries, 0 to 116148\n",
      "Data columns (total 52 columns):\n",
      " #   Column                      Non-Null Count   Dtype \n",
      "---  ------                      --------------   ----- \n",
      " 0   NCT Number                  116149 non-null  object\n",
      " 1   Study Title                 116149 non-null  object\n",
      " 2   Acronym                     116149 non-null  object\n",
      " 3   Brief Summary               116149 non-null  object\n",
      " 4   Conditions                  116149 non-null  object\n",
      " 5   Interventions               116149 non-null  object\n",
      " 6   Primary Outcome Measures    116149 non-null  object\n",
      " 7   Secondary Outcome Measures  116149 non-null  object\n",
      " 8   Other Outcome Measures      116149 non-null  object\n",
      " 9   Sponsor                     116149 non-null  object\n",
      " 10  Study Design                116149 non-null  object\n",
      " 11  Masking                     116149 non-null  object\n",
      " 12  Masking Type                116149 non-null  object\n",
      " 13  Maskings                    116149 non-null  object\n",
      " 14  Masking1                    116149 non-null  object\n",
      " 15  Masking2                    35649 non-null   object\n",
      " 16  Masking3                    22138 non-null   object\n",
      " 17  Masking4                    15217 non-null   object\n",
      " 18  Masking Description         116149 non-null  object\n",
      " 19  Drug                        116149 non-null  object\n",
      " 20  Device                      116149 non-null  object\n",
      " 21  Procedure                   116149 non-null  object\n",
      " 22  Biological                  116149 non-null  object\n",
      " 23  Other                       9117 non-null    object\n",
      " 24  Combination Product         647 non-null     object\n",
      " 25  Behavioral                  825 non-null     object\n",
      " 26  Dietary Supplement          2220 non-null    object\n",
      " 27  Genetic                     116149 non-null  object\n",
      " 28  Diaganostic Test            116149 non-null  object\n",
      " 29  Radiation                   116149 non-null  object\n",
      " 30  Population                  116149 non-null  object\n",
      " 31  Criteria                    116096 non-null  object\n",
      " 32  Gender Description          116149 non-null  object\n",
      " 33  Inclusion Criteria          103939 non-null  object\n",
      " 34  Exclusion Criteria          104848 non-null  object\n",
      " 35  Sex                         116149 non-null  object\n",
      " 36  Age                         116149 non-null  object\n",
      " 37  Phases                      116149 non-null  object\n",
      " 38  Study Type                  116149 non-null  object\n",
      " 39  Allocation                  116149 non-null  object\n",
      " 40  Intervention Model          116149 non-null  object\n",
      " 41  Primary Purpose             116149 non-null  object\n",
      " 42  Time Perspective            116149 non-null  object\n",
      " 43  Sampling Method             116149 non-null  object\n",
      " 44  Gender                      116149 non-null  object\n",
      " 45  Minimum Age                 116149 non-null  object\n",
      " 46  Maximum Age                 116149 non-null  object\n",
      " 47  Healthy Volunteers          116149 non-null  object\n",
      " 48  Gender Based                116149 non-null  object\n",
      " 49  Adult                       116149 non-null  object\n",
      " 50  Child                       116149 non-null  object\n",
      " 51  Older Adult                 116149 non-null  object\n",
      "dtypes: object(52)\n",
      "memory usage: 46.1+ MB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop(columns=[\"Study Design\", \"Maskings\",\"Masking\",\"Masking Type\", \"Masking1\", \"Masking2\", \"Masking3\", \"Masking4\", \"Criteria\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Other\"\n",
    "final_df[col] = final_df[col].fillna(\"None\")\n",
    "col = \"Combination Product\"\n",
    "final_df[col] = final_df[col].fillna(\"None\")\n",
    "col = \"Behavioral\"\n",
    "final_df[col] = final_df[col].fillna(\"None\")\n",
    "col = \"Dietary Supplement\"\n",
    "final_df[col] = final_df[col].fillna(\"None\")\n",
    "col = \"Inclusion Criteria\"\n",
    "final_df[col] = final_df[col].fillna(\"None\")\n",
    "col = \"Exclusion Criteria\"\n",
    "final_df[col] = final_df[col].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCT Number                    0\n",
       "Study Title                   0\n",
       "Acronym                       0\n",
       "Brief Summary                 0\n",
       "Conditions                    0\n",
       "Interventions                 0\n",
       "Primary Outcome Measures      0\n",
       "Secondary Outcome Measures    0\n",
       "Other Outcome Measures        0\n",
       "Sponsor                       0\n",
       "Masking Description           0\n",
       "Drug                          0\n",
       "Device                        0\n",
       "Procedure                     0\n",
       "Biological                    0\n",
       "Other                         0\n",
       "Combination Product           0\n",
       "Behavioral                    0\n",
       "Dietary Supplement            0\n",
       "Genetic                       0\n",
       "Diaganostic Test              0\n",
       "Radiation                     0\n",
       "Population                    0\n",
       "Gender Description            0\n",
       "Inclusion Criteria            0\n",
       "Exclusion Criteria            0\n",
       "Sex                           0\n",
       "Age                           0\n",
       "Phases                        0\n",
       "Study Type                    0\n",
       "Allocation                    0\n",
       "Intervention Model            0\n",
       "Primary Purpose               0\n",
       "Time Perspective              0\n",
       "Sampling Method               0\n",
       "Gender                        0\n",
       "Minimum Age                   0\n",
       "Maximum Age                   0\n",
       "Healthy Volunteers            0\n",
       "Gender Based                  0\n",
       "Adult                         0\n",
       "Child                         0\n",
       "Older Adult                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = final_df.isnull().sum()\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device Count: 1\n",
      "GPU 0: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check CUDA availability\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# List all GPUs\n",
    "device_count = torch.cuda.device_count()\n",
    "print(\"Device Count:\", device_count)\n",
    "\n",
    "# Print the name of each GPU\n",
    "for i in range(device_count):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Study Title\", \"Brief Summary\", \"Conditions\", \"Interventions\", \"Primary Outcome Measures\", \"Secondary Outcome Measures\",\n",
    "           \"Other Outcome Measures\", \"Masking Description\", \"Drug\", \"Device\", \"Procedure\", \"Biological\", \"Other\", \"Combination Product\",\n",
    "           \"Behavioral\", \"Dietary Supplement\", \"Genetic\", \"Diaganostic Test\", \"Radiation\", \"Population\", \"Gender Description\",\n",
    "           \"Inclusion Criteria\", \"Inclusion Criteria\", \"Exclusion Criteria\",\"Acronym\", \"Sponsor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for col in columns:\n",
    "    if col not in final_df.columns:  # Check if 'col' exists in 'final_df'\n",
    "        print(col)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: Study Title | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:   4%|▍         | 1/26 [41:16<17:11:47, 2476.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Brief Summary | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:   8%|▊         | 2/26 [1:32:34<18:52:03, 2830.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Conditions | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  12%|█▏        | 3/26 [2:20:37<18:14:13, 2854.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Interventions | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  15%|█▌        | 4/26 [3:11:25<17:54:41, 2930.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Primary Outcome Measures | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  19%|█▉        | 5/26 [4:19:44<19:33:10, 3351.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Secondary Outcome Measures | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  23%|██▎       | 6/26 [5:54:44<23:03:29, 4150.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Other Outcome Measures | Row: 116149/116149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  27%|██▋       | 7/26 [6:39:52<19:24:54, 3678.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: Masking Description | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  31%|███       | 8/26 [7:23:03<16:39:48, 3332.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Drug | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  35%|███▍      | 9/26 [8:09:36<14:56:22, 3163.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Device | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  38%|███▊      | 10/26 [9:07:05<14:27:09, 3251.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Procedure | Row: 116149/116149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  42%|████▏     | 11/26 [10:01:42<13:34:56, 3259.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: Biological | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  46%|████▌     | 12/26 [10:57:30<12:46:51, 3286.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Other | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  50%|█████     | 13/26 [11:52:57<11:54:42, 3298.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Combination Product | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  54%|█████▍    | 14/26 [12:50:32<11:09:12, 3346.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Behavioral | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  58%|█████▊    | 15/26 [13:53:42<10:37:56, 3479.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Dietary Supplement | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  62%|██████▏   | 16/26 [14:50:17<9:35:43, 3454.36s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Genetic | Row: 116149/116149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  65%|██████▌   | 17/26 [15:53:09<8:52:27, 3549.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: Diaganostic Test | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  69%|██████▉   | 18/26 [16:47:06<7:40:46, 3455.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Radiation | Row: 116149/116149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  73%|███████▎  | 19/26 [17:37:44<6:28:31, 3330.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: Population | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  77%|███████▋  | 20/26 [18:31:55<5:30:38, 3306.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Gender Description | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  81%|████████  | 21/26 [19:23:06<4:29:39, 3235.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Inclusion Criteria | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  85%|████████▍ | 22/26 [20:47:29<4:12:16, 3784.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Inclusion Criteria | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  88%|████████▊ | 23/26 [22:11:13<3:27:48, 4156.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Exclusion Criteria | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  92%|█████████▏| 24/26 [23:46:27<2:34:07, 4623.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Acronym | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns:  96%|█████████▌| 25/26 [24:39:18<1:09:47, 4187.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing column: Sponsor | Row: 116149/116149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns: 100%|██████████| 26/26 [25:33:36<00:00, 3908.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns: 100%|██████████| 26/26 [25:33:36<00:00, 3539.09s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# Work on a copy to preserve the original DataFrame\n",
    "vector_df = df.copy()\n",
    "\n",
    "# Wrap columns in tqdm for column-level progress\n",
    "for col in tqdm(columns, desc=\"Processing columns\"):\n",
    "    if col in df.columns:  # Ensure the column exists in the DataFrame\n",
    "        try:\n",
    "            # Create a placeholder for the vectorized column\n",
    "            vector_column = [None] * len(df)\n",
    "\n",
    "            # Use enumerate with tqdm to track row processing\n",
    "            for idx, x in enumerate(df[col].astype(str)):\n",
    "                # Print progress dynamically for rows within the column\n",
    "                sys.stdout.write(f\"\\rProcessing column: {col} | Row: {idx + 1}/{len(df)}\")\n",
    "                sys.stdout.flush()\n",
    "                vector_column[idx] = model.encode(x) if isinstance(x, str) else None\n",
    "\n",
    "            # Assign the processed data to the new column\n",
    "            vector_df[col + \" Vector\"] = vector_column\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError in column: {col}\")\n",
    "            print(f\"Sample value: {df[col].iloc[0]}\")  # Print a sample value from the column\n",
    "            print(f\"Error details: {e}\")\n",
    "    print()  # Ensure a new line after processing each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vector_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_body()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_chunk(start_i, end_i)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:324\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[0;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[1;32m--> 324\u001b[0m libwriters\u001b[38;5;241m.\u001b[39mwrite_csv_rows(\n\u001b[0;32m    325\u001b[0m     data,\n\u001b[0;32m    326\u001b[0m     ix,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols,\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter,\n\u001b[0;32m    330\u001b[0m )\n",
      "File \u001b[1;32mwriters.pyx:73\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\arrayprint.py:1612\u001b[0m, in \u001b[0;36m_array_str_implementation\u001b[1;34m(a, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m   1607\u001b[0m     \u001b[38;5;66;03m# obtain a scalar and call str on it, avoiding problems for subclasses\u001b[39;00m\n\u001b[0;32m   1608\u001b[0m     \u001b[38;5;66;03m# for which indexing with () returns a 0d instead of a scalar by using\u001b[39;00m\n\u001b[0;32m   1609\u001b[0m     \u001b[38;5;66;03m# ndarray's getindex. Also guard against recursive 0d object arrays.\u001b[39;00m\n\u001b[0;32m   1610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _guarded_repr_or_str(np\u001b[38;5;241m.\u001b[39mndarray\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(a, ()))\n\u001b[1;32m-> 1612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array2string(a, max_line_width, precision, suppress_small, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\arrayprint.py:736\u001b[0m, in \u001b[0;36marray2string\u001b[1;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, legacy)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _array2string(a, options, separator, prefix)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\arrayprint.py:513\u001b[0m, in \u001b[0;36m_recursive_guard.<locals>.decorating_function.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m repr_running\u001b[38;5;241m.\u001b[39madd(key)\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    515\u001b[0m     repr_running\u001b[38;5;241m.\u001b[39mdiscard(key)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\arrayprint.py:546\u001b[0m, in \u001b[0;36m_array2string\u001b[1;34m(a, options, separator, prefix)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;66;03m# skip over array(\u001b[39;00m\n\u001b[0;32m    544\u001b[0m next_line_prefix \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(prefix)\n\u001b[1;32m--> 546\u001b[0m lst \u001b[38;5;241m=\u001b[39m _formatArray(a, format_function, options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinewidth\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    547\u001b[0m                    next_line_prefix, separator, options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medgeitems\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    548\u001b[0m                    summary_insert, options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlegacy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lst\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\arrayprint.py:889\u001b[0m, in \u001b[0;36m_formatArray\u001b[1;34m(a, format_function, line_width, next_line_prefix, separator, edge_items, summary_insert, legacy)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;66;03m# invoke the recursive part with an initial index and prefix\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recurser(index\u001b[38;5;241m=\u001b[39m(),\n\u001b[0;32m    890\u001b[0m                     hanging_indent\u001b[38;5;241m=\u001b[39mnext_line_prefix,\n\u001b[0;32m    891\u001b[0m                     curr_width\u001b[38;5;241m=\u001b[39mline_width)\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# recursive closures have a cyclic reference to themselves, which\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;66;03m# requires gc to collect (gh-10620). To avoid this problem, for\u001b[39;00m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;66;03m# performance and PyPy friendliness, we break the cycle:\u001b[39;00m\n\u001b[0;32m    896\u001b[0m     recurser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\arrayprint.py:846\u001b[0m, in \u001b[0;36m_formatArray.<locals>.recurser\u001b[1;34m(index, hanging_indent, curr_width)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trailing_items, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    845\u001b[0m     word \u001b[38;5;241m=\u001b[39m recurser(index \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m-\u001b[39mi,), next_hanging_indent, next_width)\n\u001b[1;32m--> 846\u001b[0m     s, line \u001b[38;5;241m=\u001b[39m _extendLine_pretty(\n\u001b[0;32m    847\u001b[0m         s, line, word, elem_width, hanging_indent, legacy)\n\u001b[0;32m    848\u001b[0m     line \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m separator\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m legacy \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m113\u001b[39m:\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;66;03m# width of the separator is not considered on 1.13\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\arrayprint.py:757\u001b[0m, in \u001b[0;36m_extendLine_pretty\u001b[1;34m(s, line, word, line_width, next_line_prefix, legacy)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_extendLine_pretty\u001b[39m(s, line, word, line_width, next_line_prefix, legacy):\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m    Extends line with nicely formatted (possibly multi-line) string ``word``.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     words \u001b[38;5;241m=\u001b[39m word\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(words) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m legacy \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m113\u001b[39m:\n\u001b[0;32m    759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _extendLine(s, line, word, line_width, next_line_prefix, legacy)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vector_df.to_csv(\"vector_data.csv\", index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "malloc of size 536870912 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vector_df\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector_data.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3113\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   3032\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3033\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[0;32m   3034\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3109\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[0;32m   3110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 3113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_parquet(\n\u001b[0;32m   3114\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3115\u001b[0m     path,\n\u001b[0;32m   3116\u001b[0m     engine,\n\u001b[0;32m   3117\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3118\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   3119\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m   3120\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3121\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3122\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:480\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m    478\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m--> 480\u001b[0m impl\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m    481\u001b[0m     df,\n\u001b[0;32m    482\u001b[0m     path_or_buf,\n\u001b[0;32m    483\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    484\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    485\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m    486\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    487\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    489\u001b[0m )\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io\u001b[38;5;241m.\u001b[39mBytesIO)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:190\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[1;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     from_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreserve_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m--> 190\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_pandas(df, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfrom_pandas_kwargs)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[0;32m    193\u001b[0m     df_metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPANDAS_ATTRS\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(df\u001b[38;5;241m.\u001b[39mattrs)}\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:624\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[1;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m--> 624\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m maybe_fut\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    626\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39marray(col, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtype_, from_pandas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, safe\u001b[38;5;241m=\u001b[39msafe)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[0;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: malloc of size 536870912 failed"
     ]
    }
   ],
   "source": [
    "vector_df.to_parquet(\"vector_data.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_vector_df_to_parquet_in_chunks(vector_df, output_file_prefix=\"vector_data\", num_chunks=10):\n",
    "    \"\"\"\n",
    "    Saves a pandas DataFrame with vector columns to Parquet files in multiple chunks.\n",
    "\n",
    "    Args:\n",
    "        vector_df: The pandas DataFrame containing vector data.\n",
    "        output_file_prefix: The prefix for the output Parquet files.\n",
    "        num_chunks: The number of chunks to split the DataFrame into.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    chunk_size = len(vector_df) // num_chunks\n",
    "    for i in range(num_chunks):\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = (i + 1) * chunk_size if i < num_chunks - 1 else len(vector_df)\n",
    "        chunk_df = vector_df[start_idx:end_idx]\n",
    "\n",
    "        print(f\"Processing Chunk {i+1}/{num_chunks}\")\n",
    "        chunk_df.to_parquet(f\"{output_file_prefix}_{i}.parquet\", index=False)\n",
    "\n",
    "def read_vector_df_from_parquet_chunks(output_file_prefix=\"vector_data\", num_chunks=10):\n",
    "    \"\"\"\n",
    "    Reads multiple Parquet files containing vector data and concatenates them into a single DataFrame.\n",
    "\n",
    "    Args:\n",
    "        output_file_prefix: The prefix for the output Parquet files.\n",
    "        num_chunks: The number of chunks.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the concatenated vector data.\n",
    "    \"\"\"\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(num_chunks):\n",
    "        chunk_path = f\"{output_file_prefix}_{i}.parquet\"\n",
    "        if os.path.exists(chunk_path):\n",
    "            chunk_df = pd.read_parquet(chunk_path)\n",
    "            chunks.append(chunk_df)\n",
    "\n",
    "    if chunks:\n",
    "        return pd.concat(chunks, ignore_index=True)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chunk 1/10\n"
     ]
    },
    {
     "ename": "ArrowMemoryError",
     "evalue": "malloc of size 67108864 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example Usage:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming 'vector_df' is your DataFrame\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m save_vector_df_to_parquet_in_chunks(vector_df)\n",
      "Cell \u001b[1;32mIn[25], line 25\u001b[0m, in \u001b[0;36msave_vector_df_to_parquet_in_chunks\u001b[1;34m(vector_df, output_file_prefix, num_chunks)\u001b[0m\n\u001b[0;32m     22\u001b[0m chunk_df \u001b[38;5;241m=\u001b[39m vector_df[start_idx:end_idx]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m chunk_df\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3113\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   3032\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3033\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[0;32m   3034\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3109\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[0;32m   3110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 3113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_parquet(\n\u001b[0;32m   3114\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3115\u001b[0m     path,\n\u001b[0;32m   3116\u001b[0m     engine,\n\u001b[0;32m   3117\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3118\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   3119\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m   3120\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3121\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3122\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:480\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m    478\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m--> 480\u001b[0m impl\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m    481\u001b[0m     df,\n\u001b[0;32m    482\u001b[0m     path_or_buf,\n\u001b[0;32m    483\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    484\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    485\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m    486\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    487\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    489\u001b[0m )\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io\u001b[38;5;241m.\u001b[39mBytesIO)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:190\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[1;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     from_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreserve_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m--> 190\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_pandas(df, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfrom_pandas_kwargs)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[0;32m    193\u001b[0m     df_metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPANDAS_ATTRS\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(df\u001b[38;5;241m.\u001b[39mattrs)}\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:624\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[1;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m--> 624\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m maybe_fut\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    626\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39marray(col, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtype_, from_pandas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, safe\u001b[38;5;241m=\u001b[39msafe)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[0;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: malloc of size 67108864 failed"
     ]
    }
   ],
   "source": [
    "# Example Usage:\n",
    "# Assuming 'vector_df' is your DataFrame\n",
    "save_vector_df_to_parquet_in_chunks(vector_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the data back into a single DataFrame\n",
    "combined_df = read_vector_df_from_parquet_chunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m vector_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "vector_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate DataFrame size in memory: 1.44 GB\n",
      "Estimated CSV file size: 1.58 GB\n"
     ]
    }
   ],
   "source": [
    "df_size = vector_df.memory_usage(deep=True).sum()\n",
    "print(f\"Approximate DataFrame size in memory: {df_size / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "# Estimated CSV size (adjust for overhead)\n",
    "csv_size = df_size * 1.1  # CSV overhead for delimiters and newlines\n",
    "print(f\"Estimated CSV file size: {csv_size / (1024 ** 3):.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCT Number                                                         NCT02259894\n",
       "Study Title                  Safety, Pharmacokinetics, and Pharmacodynamics...\n",
       "Acronym                                                          Not Available\n",
       "Brief Summary                To assess safety, tolerability, pharmacokineti...\n",
       "Conditions                                                             Healthy\n",
       "                                                   ...                        \n",
       "Gender Description Vector    [0.053648673, 0.042725515, 0.019215602, -0.037...\n",
       "Inclusion Criteria Vector    [0.018984854, -0.027502565, 0.00038148998, -0....\n",
       "Exclusion Criteria Vector    [0.013192763, -0.029652162, 0.013258504, -0.05...\n",
       "Acronym Vector               [0.047543935, -0.021916235, 0.030107958, 0.035...\n",
       "Sponsor Vector               [-0.011009573, -0.08571944, 0.004269253, 0.035...\n",
       "Name: 27, Length: 68, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "vector_df.iloc[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from typing import List, Dict, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "# Create collection for clinical trials\n",
    "collection = client.create_collection(\n",
    "    name=\"clinical_trials\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "weights = {\n",
    "    'Study Title Vector': 1.4,\n",
    "    'Brief Summary Vector': 1.5,\n",
    "    'Conditions Vector': 1.0,\n",
    "    'Interventions Vector': 0.8,\n",
    "    'Primary Outcome Measures Vector': 1.2,\n",
    "    'Secondary Outcome Measures Vector': 0.6,\n",
    "    'Other Outcome Measures Vector': 0.2,\n",
    "    'Masking Description Vector': 1.2,\n",
    "    'Drug Vector': 1.0,\n",
    "    'Device Vector': 0.8,\n",
    "    'Procedure Vector': 0.5,\n",
    "    'Biological Vector': 0.5,\n",
    "    'Other Vector': 0.5,\n",
    "    'Combination Product Vector': 0.5,\n",
    "    'Behavioral Vector': 0.5,\n",
    "    'Dietary Supplement Vector': 0.8,\n",
    "    'Genetic Vector': 0.8,\n",
    "    'Diaganostic Test Vector': 1.0,\n",
    "    'Radiation Vector': 0.6,\n",
    "    'Population Vector': 0.7,\n",
    "    'Gender Description Vector': 1.0,\n",
    "    'Inclusion Criteria Vector': 1.3,\n",
    "    'Exclusion Criteria Vector': 1.3,\n",
    "    'Acronym Vector': 0.5,\n",
    "    'Sponsor Vector': 0.7\n",
    "}\n",
    "\n",
    "# Extract vector columns and apply weights\n",
    "weighted_vectors = []\n",
    "for col in weights:\n",
    "    weighted_vectors.append(np.array([np.array(vec) * weights[col] for vec in vector_df[col].values]))\n",
    "\n",
    "# Combine weighted vectors into a single matrix\n",
    "vectors = np.array([np.concatenate(row) for row in zip(*weighted_vectors)])\n",
    "\n",
    "# Normalize vectors for cosine similarity search\n",
    "faiss.normalize_L2(vectors)\n",
    "\n",
    "# Create a FAISS index\n",
    "dimension = vectors.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # IP = Inner Product for cosine similarity\n",
    "index.add(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_filters(nct_number, filters, k, weights, apply_filter):\n",
    "    \"\"\"\n",
    "    Perform semantic search using NCT Number as query and apply filters.\n",
    "\n",
    "    :param nct_number: The NCT Number of the query.\n",
    "    :param filters: A dictionary of filters to apply, e.g., {\"Sex\": \"Male\", \"Age\": \"18-65\"}.\n",
    "    :param k: Number of results to return.\n",
    "    :param apply_filter: Whether to apply filters (\"Y\" for yes).\n",
    "    :return: Filtered search results with similarity scores.\n",
    "    \"\"\"\n",
    "    # Get the query vector for the given NCT Number\n",
    "    query_vector = vectors[df[df['NCT Number'] == nct_number].index[0]]\n",
    "\n",
    "    # Normalize the query vector\n",
    "    query_vector = query_vector / np.linalg.norm(query_vector)\n",
    "\n",
    "    # Perform the search\n",
    "    distances, indices = index.search(np.array([query_vector]), k=k + 1)  # Add 1 to exclude the query itself\n",
    "\n",
    "    # Get search results\n",
    "    results = df.iloc[indices[0]]\n",
    "    results[\"Similarity Score\"] = distances[0]\n",
    "\n",
    "        # Apply filters and weights\n",
    "    if apply_filter == \"Y\":\n",
    "        weighted_scores = []\n",
    "        for _, row in results.iterrows():\n",
    "            weighted_score = row['Similarity Score']  # Start with similarity score\n",
    "            for col, value in filters.items():\n",
    "                if row[col] == value:\n",
    "                    weighted_score += weights.get(col, 0)  # Add the weight if filter matches\n",
    "            weighted_scores.append(weighted_score)\n",
    "\n",
    "        # Add weighted scores to results and sort by it\n",
    "        results['Weighted Score'] = weighted_scores\n",
    "        results = results.sort_values(by='Weighted Score', ascending=False)\n",
    "\n",
    "    # Exclude the original query from the results\n",
    "    results = results[results[\"NCT Number\"] != nct_number]\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nct_number = str(input(\"Enter the NCT Number to Search: \")) # Replace with your actual NCT Number\n",
    "if nct_number in df['NCT Number'].values:  # Check if NCT Number exists\n",
    "    filters = {\n",
    "        \"Sex\": df.loc[df['NCT Number'] == nct_number, 'Sex'].iloc[0],\n",
    "        \"Phases\": df.loc[df['NCT Number'] == nct_number, 'Phases'].iloc[0],\n",
    "        \"Study Type\": df.loc[df['NCT Number'] == nct_number, 'Study Type'].iloc[0],\n",
    "        \"Allocation\": df.loc[df['NCT Number'] == nct_number, 'Allocation'].iloc[0],\n",
    "        \"Intervention Model\": df.loc[df['NCT Number'] == nct_number, 'Intervention Model'].iloc[0],\n",
    "        \"Primary Purpose\": df.loc[df['NCT Number'] == nct_number, 'Primary Purpose'].iloc[0],\n",
    "        \"Time Perspective\": df.loc[df['NCT Number'] == nct_number, 'Time Perspective'].iloc[0],\n",
    "        \"Sampling Method\": df.loc[df['NCT Number'] == nct_number, 'Sampling Method'].iloc[0],\n",
    "        \"Gender\": df.loc[df['NCT Number'] == nct_number, 'Gender'].iloc[0],\n",
    "        \"Healthy Volunteers\": df.loc[df['NCT Number'] == nct_number, 'Healthy Volunteers'].iloc[0],\n",
    "        \"Gender Based\": df.loc[df['NCT Number'] == nct_number, 'Gender Based'].iloc[0],\n",
    "        \"Adult\": df.loc[df['NCT Number'] == nct_number, 'Adult'].iloc[0],\n",
    "        \"Child\": df.loc[df['NCT Number'] == nct_number, 'Child'].iloc[0],\n",
    "        \"Older Adult\": df.loc[df['NCT Number'] == nct_number, 'Older Adult'].iloc[0],\n",
    "    }\n",
    "else:\n",
    "    print(f\"NCT Number '{nct_number}' not found in the dataset.\")\n",
    "    filters = None\n",
    "\n",
    "k = int(input(\"Number of Search Results you Want: \"))\n",
    "apply_filters = str(input(\"Type 'Y': If you want to apply FIlter0s: \"))\n",
    "weights = {\n",
    "    \"Sex\": 0.2,\n",
    "    \"Phases\": 0.3,\n",
    "    \"Study Type\": 0.1,\n",
    "    \"Allocation\": 0.15,\n",
    "    \"Intervention Model\": 0.25,\n",
    "    \"Primary Purpose\": 0.2,\n",
    "    \"Time Perspective\": 0.1,\n",
    "    \"Sampling Method\": 0.05,\n",
    "    \"Gender\": 0.15,\n",
    "    \"Healthy Volunteers\": 0.1,\n",
    "    \"Gender Based\": 0.05,\n",
    "    \"Adult\": 0.1,\n",
    "    \"Child\": 0.1,\n",
    "    \"Older Adult\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dheer\\AppData\\Local\\Temp\\ipykernel_7920\\3212742788.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results[\"Similarity Score\"] = distances[0]\n",
      "C:\\Users\\dheer\\AppData\\Local\\Temp\\ipykernel_7920\\3212742788.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['Weighted Score'] = weighted_scores\n"
     ]
    }
   ],
   "source": [
    "search_results = search_with_filters(nct_number, filters, k,weights, apply_filters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCT Number</th>\n",
       "      <th>Study Title</th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>Weighted Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NCT01515891</td>\n",
       "      <td>Absorption, Distribution, Metabolism and Excre...</td>\n",
       "      <td>0.696261</td>\n",
       "      <td>2.246261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NCT06009094</td>\n",
       "      <td>Safety, Tolerance and Pharmacokinetics Clinica...</td>\n",
       "      <td>0.662448</td>\n",
       "      <td>2.162448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NCT03609294</td>\n",
       "      <td>A Clinical Trial to Evaluate the Pharmacokinet...</td>\n",
       "      <td>0.654846</td>\n",
       "      <td>2.154846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NCT01959594</td>\n",
       "      <td>A Study To Observe Safety And Blood Concentrat...</td>\n",
       "      <td>0.749562</td>\n",
       "      <td>2.149562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT03302091</td>\n",
       "      <td>A Study in People With Normal Kidney Function ...</td>\n",
       "      <td>0.706545</td>\n",
       "      <td>2.056545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>NCT05732194</td>\n",
       "      <td>Multiple Ascending Dose Study to Evaluate the ...</td>\n",
       "      <td>0.699956</td>\n",
       "      <td>2.049956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NCT04480294</td>\n",
       "      <td>A Phase I Study to Evaluate the Safety, Tolera...</td>\n",
       "      <td>0.691102</td>\n",
       "      <td>1.891102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NCT03591094</td>\n",
       "      <td>Study Assessing PTI-428 Safety, Tolerability, ...</td>\n",
       "      <td>0.642920</td>\n",
       "      <td>1.742920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>NCT00650494</td>\n",
       "      <td>Fed Study of Valacyclovir Hydrochloride Tablet...</td>\n",
       "      <td>0.676584</td>\n",
       "      <td>1.726584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NCT02019394</td>\n",
       "      <td>Absolute Bioavailability of Lu AE58054 in Heal...</td>\n",
       "      <td>0.683113</td>\n",
       "      <td>1.683113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NCT Number                                        Study Title  \\\n",
       "48  NCT01515891  Absorption, Distribution, Metabolism and Excre...   \n",
       "41  NCT06009094  Safety, Tolerance and Pharmacokinetics Clinica...   \n",
       "25  NCT03609294  A Clinical Trial to Evaluate the Pharmacokinet...   \n",
       "99  NCT01959594  A Study To Observe Safety And Blood Concentrat...   \n",
       "0   NCT03302091  A Study in People With Normal Kidney Function ...   \n",
       "71  NCT05732194  Multiple Ascending Dose Study to Evaluate the ...   \n",
       "24  NCT04480294  A Phase I Study to Evaluate the Safety, Tolera...   \n",
       "21  NCT03591094  Study Assessing PTI-428 Safety, Tolerability, ...   \n",
       "81  NCT00650494  Fed Study of Valacyclovir Hydrochloride Tablet...   \n",
       "9   NCT02019394  Absolute Bioavailability of Lu AE58054 in Heal...   \n",
       "\n",
       "    Similarity Score  Weighted Score  \n",
       "48          0.696261        2.246261  \n",
       "41          0.662448        2.162448  \n",
       "25          0.654846        2.154846  \n",
       "99          0.749562        2.149562  \n",
       "0           0.706545        2.056545  \n",
       "71          0.699956        2.049956  \n",
       "24          0.691102        1.891102  \n",
       "21          0.642920        1.742920  \n",
       "81          0.676584        1.726584  \n",
       "9           0.683113        1.683113  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results[[\"NCT Number\",\"Study Title\",\"Similarity Score\",\"Weighted Score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
